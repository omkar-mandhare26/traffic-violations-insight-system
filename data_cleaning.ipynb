{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ea565f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import (\n",
    "    clean_date_of_stop,\n",
    "    clean_latitude, clean_longitude,\n",
    "    clean_description,\n",
    "    invalid_driver_city, prefix_mapping,\n",
    "    format_and_clean_geolocation, validate_geolocation, geo_to_string,\n",
    "    clean_location,\n",
    "    invalid_make,\n",
    "    invalid_model,\n",
    "    clean_time_of_stop\n",
    ")\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "\n",
    "try:\n",
    "    violations_df = pd.read_csv(\"./dataset/Traffic_Violations.csv\")\n",
    "except FileNotFoundError:\n",
    "    raise FileNotFoundError(\"CSV file not found at ./dataset/Traffic_Violations.csv\")\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"Unexpected error while loading CSV: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb4ea8f",
   "metadata": {},
   "source": [
    "<h1><b>SeqID</b></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9214d8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Dropping duplicate SeqID's \n",
    "    violations_df = violations_df.drop_duplicates(subset=['SeqID'], keep='first')\n",
    "\n",
    "    violations_df = violations_df.reset_index(drop=True)\n",
    "\n",
    "    violations_df[\"SeqID\"] = violations_df[\"SeqID\"].astype(\"string\")\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"Error while processing SeqID column: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f10a2a7",
   "metadata": {},
   "source": [
    "<h1><b>Date Of Stop</b></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cfdb2708",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    violations_df[\"Date Of Stop\"] = violations_df[\"Date Of Stop\"].apply(clean_date_of_stop)\n",
    "\n",
    "    violations_df.dropna(subset=[\"Date Of Stop\"], inplace=True)\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"Error while cleaning Date Of Stop column: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45aba64",
   "metadata": {},
   "source": [
    "<h1><b>Time Of Stop</b></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6ed7e5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    violations_df[\"Time Of Stop\"] = violations_df[\"Time Of Stop\"].apply(clean_time_of_stop)\n",
    "\n",
    "    violations_df.dropna(subset=[\"Time Of Stop\"], inplace=True)\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"Error while cleaning Time Of Stop column: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1c21ce",
   "metadata": {},
   "source": [
    "<h1><b>Agency</b></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e7e335a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Normalizing text case for consistent values\n",
    "    violations_df[\"Agency\"] = violations_df[\"Agency\"].str.upper()\n",
    "except Exception as e: \n",
    "    raise RuntimeError(f\"Error while tranforming Agency: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd51615b",
   "metadata": {},
   "source": [
    "<h1><b>SubAgency</b></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0e0b0a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    violations_df = violations_df.rename(columns={\"SubAgency\": \"Sub Agency\"})\n",
    "\n",
    "    # Removing extra spaces around slash\n",
    "    violations_df[\"Sub Agency\"] = violations_df[\"Sub Agency\"].apply(lambda x: re.sub(r'\\s*/\\s*', '/', x))\n",
    "except Exception as e: \n",
    "    raise RuntimeError(f\"Error while tranforming Sub Agency: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06062660",
   "metadata": {},
   "source": [
    "<h1><b>Description</b></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f598269a",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    violations_df[\"Description\"] = violations_df[\"Description\"].apply(clean_description)\n",
    "    \n",
    "    violations_df.dropna(subset=[\"Description\"], inplace=True)\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"Error while cleaning Description column: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff8096a",
   "metadata": {},
   "source": [
    "<h1><b>Location</b></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "81dd54e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    violations_df[\"Location\"] = violations_df[\"Location\"].apply(clean_location)\n",
    "\n",
    "    violations_df.dropna(subset=[\"Location\"], inplace=True)\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"Error while cleaning Location column: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb5bfda",
   "metadata": {},
   "source": [
    "<h1><b>Latitude & Longitude</b></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "84315dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Converting data to float and rounding to 6 decimal places\n",
    "    violations_df[\"Latitude\"] = pd.to_numeric(violations_df[\"Latitude\"], errors=\"coerce\").astype(\"float64\").round(6)\n",
    "    \n",
    "    violations_df[\"Latitude\"] = violations_df[\"Latitude\"].apply(clean_latitude)\n",
    "    \n",
    "    violations_df.dropna(subset=[\"Latitude\"], inplace=True)\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"Error while cleaning Latitude column: {e}\")\n",
    "\n",
    "try:\n",
    "    # Converting data to float and rounding to 6 decimal places\n",
    "    violations_df[\"Longitude\"] = pd.to_numeric(violations_df[\"Longitude\"], errors=\"coerce\").astype(\"float64\").round(6)\n",
    "    \n",
    "    violations_df[\"Longitude\"] = violations_df[\"Longitude\"].apply(clean_longitude)\n",
    "    \n",
    "    violations_df.dropna(subset=[\"Longitude\"], inplace=True)\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"Error while cleaning Longitude column: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded78b3b",
   "metadata": {},
   "source": [
    "<h1><b>Accident, Belts, Personal Injury, Property Damage, Fatal, Commercial License, HAZMAT, Commercial Vehicle, Alcohol, Work Zone, Search Conducted</b></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ccfd2095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data transforming to categorical columns which are having values True & False\n",
    "cols = [\"Accident\", \"Belts\", \"Personal Injury\", \"Property Damage\", \"Fatal\", \"Commercial License\", \"HAZMAT\", \"Commercial Vehicle\", \"Alcohol\", \"Work Zone\", \"Search Conducted\"]\n",
    "\n",
    "mapping = {\n",
    "        'y': 'true',\n",
    "        'yes': 'true',\n",
    "        'n': 'false',\n",
    "        'no': 'false',\n",
    "        '1': 'true',\n",
    "        '0': 'false',\n",
    "        'FALSE': 'false',\n",
    "        '': 'false'\n",
    "    }\n",
    "\n",
    "try:\n",
    "    for col in cols:\n",
    "        violations_df[col] = violations_df[col].replace(mapping)\n",
    "        violations_df.dropna(subset=[col], inplace=True)\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"Error while applying mapping and dropping NaNs: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a559510",
   "metadata": {},
   "source": [
    "<h1><b>Search Disposition</b></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3bfa023c",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Fixing NaN to \"Not Applicable\" & Standardizing text case\n",
    "    violations_df[\"Search Disposition\"] = violations_df[\"Search Disposition\"].apply(\n",
    "        lambda x: \"Not Applicable\" if pd.isna(x) else str(x).title() if len(str(x)) > 3 else str(x)\n",
    "    )\n",
    "except Exception as e: \n",
    "    raise RuntimeError(f\"Error while tranforming Search Disposition column: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af65f15",
   "metadata": {},
   "source": [
    "<h1><b>Search Outcome</b></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ce0c8df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    violations_df.dropna(subset=[\"Search Outcome\"], inplace=True)\n",
    "\n",
    "    # Standardizing text case\n",
    "    violations_df[\"Search Outcome\"] = violations_df[\"Search Outcome\"].apply(lambda x: str(x).title())\n",
    "except Exception as e: \n",
    "    raise RuntimeError(f\"Error while tranforming Search Outcome column: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61685c1b",
   "metadata": {},
   "source": [
    "<h1><b>Search Reason</b></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8c976baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Fixing NaN to \"Other\" & Standardizing text case\n",
    "    violations_df[\"Search Reason\"] = violations_df[\"Search Reason\"].apply(\n",
    "        lambda x: \"Other\" if pd.isna(x) else str(x).title() if len(str(x)) > 3 else x\n",
    "    )\n",
    "\n",
    "    violations_df[\"Search Reason\"] = violations_df[\"Search Reason\"].replace({\"Probable Cause For Cds\": \"Probable Cause For CDS\"})\n",
    "except Exception as e: \n",
    "    raise RuntimeError(f\"Error while tranforming Search Reason column: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a45117b",
   "metadata": {},
   "source": [
    "<h1><b>Search Reason For Stop</b></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fb8654c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    violations_df.dropna(subset=[\"Search Reason For Stop\"], inplace=True)\n",
    "\n",
    "    # Removing Noise Data\n",
    "    violations_df = violations_df[violations_df[\"Search Reason For Stop\"].str.len() > 5]\n",
    "\n",
    "    violations_df[\"Search Reason For Stop\"] = violations_df[\"Search Reason For Stop\"].apply(lambda x: str(x).upper())\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"Error while cleaning Search Reason For Stop column: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8082e85",
   "metadata": {},
   "source": [
    "<h1><b>Search Type</b></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fd088478",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Fixing NaN to \"Not Applicable\" & Standardizing text case\n",
    "    violations_df[\"Search Type\"] = violations_df[\"Search Type\"].apply(\n",
    "        lambda x: \"Not Applicable\" if pd.isna(x) else str(x).title() if len(str(x)) > 2 else x\n",
    "    )\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"Error while tranforming Search Type column: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b6dff2",
   "metadata": {},
   "source": [
    "<h1><b>Search Arrest Reason</b></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "124920d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Fixing NaN to \"Other\" & Standardizing text case\n",
    "    violations_df[\"Search Arrest Reason\"] = violations_df[\"Search Arrest Reason\"].apply(\n",
    "        lambda x: \"Other\" if pd.isna(x) else str(x).title() if len(str(x)) > 3 else x\n",
    "    )\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"Error while cleaning Search Arrest Reason column: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ce25e3",
   "metadata": {},
   "source": [
    "<h1><b>State</b></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cc3617d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    violations_df.dropna(subset=[\"State\"], inplace=True)\n",
    "\n",
    "    # Standardizing text case\n",
    "    violations_df[\"State\"] = violations_df[\"State\"].apply(lambda x: str(x).upper())\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"Error while cleaning State column: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb67462",
   "metadata": {},
   "source": [
    "<h1><b>VehicleType</b></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1be53b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {\n",
    "    \"18 - Police Vehicle\" : \"18 - Police(Non-Emerg)\",\n",
    "    \"28 - Electric Bicycle\": \"28 - Other\",\n",
    "    \"29 - Other\": \"29 - Unknown\"\n",
    "}\n",
    "\n",
    "try:\n",
    "    violations_df = violations_df.rename(columns={\"VehicleType\": \"Vehicle Type\"})\n",
    "\n",
    "    violations_df[\"Vehicle Type\"] = violations_df[\"Vehicle Type\"].replace(mapping)\n",
    "    violations_df[\"Vehicle Type\"] = violations_df[\"Vehicle Type\"].apply(lambda x: str(x).title())\n",
    "\n",
    "    # Splitting \"Vehicle Type\" into 2 column - \"Vehicle Code\", \"Vehicle Category\"\n",
    "    violations_df[[\"Vehicle Code\", \"Vehicle Category\"]] = violations_df[\"Vehicle Type\"].str.split(\" - \", n=1, expand=True)\n",
    "    violations_df[\"Vehicle Code\"] = violations_df[\"Vehicle Code\"].astype(int)\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"Error while cleaning Vehicle Type column: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28407759",
   "metadata": {},
   "source": [
    "<h1><b>Year</b></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8fe31677",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Converting data to Integers\n",
    "    violations_df[\"Year\"] = pd.to_numeric(violations_df[\"Year\"], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "    # Marking invalid data as None\n",
    "    violations_df[\"Year\"] = violations_df[\"Year\"].apply(lambda x: x if 1960 <= x <= 2025 else None)\n",
    "\n",
    "    violations_df.dropna(subset=[\"Year\"], inplace=True)\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"Error while cleaning Year column: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eccbfd1e",
   "metadata": {},
   "source": [
    "<h1><b>Make</b></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "48f75838",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:    \n",
    "    # Removing all non-alphabetic characters\n",
    "    violations_df[\"Make\"] = violations_df[\"Make\"].str.replace(r\"[^A-Za-z]\", \"\", regex=True)\n",
    "\n",
    "    # Correcting typos, abbreviations, and spelling variations \n",
    "    with open(\"./mappings/make.json\", \"r\") as f:\n",
    "        mapping = json.load(f)\n",
    "    violations_df[\"Make\"] = violations_df[\"Make\"].replace(mapping)\n",
    "\n",
    "    # Removing invalid data\n",
    "    violations_df = violations_df[~violations_df[\"Make\"].isin(invalid_make)]\n",
    "\n",
    "    violations_df.dropna(subset=[\"Make\"], inplace=True)\n",
    "except FileNotFoundError:\n",
    "    raise FileNotFoundError(\"make.json not found at ./mappings/make.json\")\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"Error while cleaning Make column: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f770fd48",
   "metadata": {},
   "source": [
    "<h1><b>Model</b></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "dfe120a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Stadardizing text case and spacing\n",
    "    violations_df[\"Model\"] = violations_df[\"Model\"].apply(\n",
    "            lambda x: \" \".join(str(x).split()).upper()\n",
    "        )\n",
    "\n",
    "    # Removing noise data\n",
    "    violations_df = violations_df[violations_df[\"Model\"].str.len()>1]\n",
    "\n",
    "    # Removing invalid data\n",
    "    violations_df = violations_df[~violations_df[\"Model\"].isin(invalid_model)]\n",
    "\n",
    "    # Correcting typos, abbreviations, and spelling variations\n",
    "    with open(\"./mappings/model.json\", \"r\") as f:\n",
    "        mapping = json.load(f)\n",
    "    violations_df[\"Model\"] = violations_df[\"Model\"].replace(mapping)\n",
    "except FileNotFoundError:\n",
    "    raise FileNotFoundError(\"model.json not found at ./mappings/model.json\")\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"Error while cleaning Model column: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f9054c",
   "metadata": {},
   "source": [
    "<h1><b>Color</b></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "28ddaa0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {\n",
    "    \"BLUE, DARK\" : \"Dark Blue\",\n",
    "    \"BLUE, LIGHT\" : \"Light Blue\",\n",
    "    \"GREEN, LGT\" : \"Light Green\",\n",
    "    \"GREEN, DK\" : \"Dark Green\"\n",
    "}\n",
    "\n",
    "try:\n",
    "    violations_df.dropna(subset=[\"Color\"], inplace=True)\n",
    "\n",
    "    violations_df[\"Color\"] = violations_df[\"Color\"].replace(mapping)\n",
    "    \n",
    "    # Standardizing text case\n",
    "    violations_df[\"Color\"] = violations_df[\"Color\"].apply(lambda x: str(x).title())\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"Error while transforming Color column: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e816dba",
   "metadata": {},
   "source": [
    "<h1><b>Violation Type</b></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "307d86fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    # Standardizing text case\n",
    "    violations_df[\"Violation Type\"] = violations_df[\"Violation Type\"].apply(lambda x: str(x).upper())\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"Error while transforming Violation Type column: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101c2eed",
   "metadata": {},
   "source": [
    "<h1><b>Charge</b></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8d9f3c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Removing noise data\n",
    "    violations_df = violations_df[violations_df[\"Charge\"].str.len() > 3]\n",
    "\n",
    "    # Standardizing text case\n",
    "    violations_df[\"Charge\"] = violations_df[\"Charge\"].apply(lambda x: str(x).upper())\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"Error while cleaning Charge column: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1343db",
   "metadata": {},
   "source": [
    "<h1><b>Article</b></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9e6e7035",
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_articles = [\"Maryland Rules\", \"00\", \"BR\", \"1A\"]\n",
    "try:\n",
    "    # Removing invalid articles (Unrelated articles)\n",
    "    violations_df = violations_df[~violations_df[\"Article\"].isin(invalid_articles)]\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"Error while cleaning Article column: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b490af49",
   "metadata": {},
   "source": [
    "<h1><b>Contributed To Accident</b></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b41a2d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Stadardizing \"Yes\" & \"No\" accross all categorical columns\n",
    "    violations_df[\"Contributed To Accident\"] = violations_df[\"Contributed To Accident\"].map({True: \"Yes\", False: \"No\"})\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"Error while converting type of 'Contributes To Accident' column: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d13feb7",
   "metadata": {},
   "source": [
    "<h1><b>Race</b></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7da355e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Standardizing text case\n",
    "    violations_df[\"Race\"] = violations_df[\"Race\"].apply(lambda x: str(x).upper())\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"Error while transforming Race column: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb89857f",
   "metadata": {},
   "source": [
    "<h1><b>Gender</b></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "43acab35",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    violations_df[\"Gender\"] = violations_df[\"Gender\"].replace({\"M\":\"Male\", \"F\":\"Female\", \"U\": \"Unknown\"})\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"Error while transforming Gender column: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9719b9a2",
   "metadata": {},
   "source": [
    "<h1><b>Driver City</b></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "627183bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    violations_df.dropna(subset=[\"Driver City\"], inplace=True)\n",
    "\n",
    "    # Removing noise data\n",
    "    violations_df = violations_df[violations_df[\"Driver City\"].str.len() > 3]\n",
    "\n",
    "    # Removing invalid cities\n",
    "    violations_df = violations_df[~violations_df[\"Driver City\"].isin(invalid_driver_city)]\n",
    "\n",
    "    # Correcting typos, abbreviations, and spelling variations\n",
    "    with open(\"./mappings/driver_city.json\", \"r\") as f:\n",
    "        mapping = json.load(f)\n",
    "    violations_df[\"Driver City\"] = violations_df[\"Driver City\"].replace(mapping)\n",
    "\n",
    "    # Expanding common abbreviations\n",
    "    for pattern, repl in prefix_mapping.items(): \n",
    "        violations_df[\"Driver City\"]  = violations_df[\"Driver City\"].str.replace(pattern, repl, regex=True)\n",
    "\n",
    "    # Standardizing text case & spaces\n",
    "    violations_df[\"Driver City\"] = violations_df[\"Driver City\"].apply(\n",
    "            lambda x: \" \".join(str(x).split()).upper()\n",
    "        )\n",
    "except FileNotFoundError:\n",
    "    raise FileNotFoundError(\"driver_city.json not found at ./mappings/driver_city.json\")\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"Error while cleaning Driver City column: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd34871b",
   "metadata": {},
   "source": [
    "<h1><b>Driver State</b></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e6e2b264",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Standardizing text case\n",
    "    violations_df[\"Driver State\"] = violations_df[\"Driver State\"].apply(lambda x: str(x).upper())\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"Error while transforming Driver State column: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70082121",
   "metadata": {},
   "source": [
    "<h1><b>DL State</b></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ad0ab2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    violations_df.dropna(subset=[\"DL State\"], inplace=True)\n",
    "\n",
    "    # Standardizing text case\n",
    "    violations_df[\"DL State\"] = violations_df[\"DL State\"].apply(lambda x: str(x).upper())\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"Error while cleaning DL State column: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6de76c",
   "metadata": {},
   "source": [
    "<h1><b>Arrest Type</b></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3ea1dfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Splitting \"Arrest Type\" into 2 columns - \"Arrest Type Code\", \"Arrest Type Description\"\n",
    "    violations_df[[\"Arrest Type Code\", \"Arrest Type Description\"]] = violations_df[\"Arrest Type\"].str.split(\" - \", n=1, expand=True)\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"Error while transforming Arrest Type column: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9ca53d",
   "metadata": {},
   "source": [
    "<h1><b>Geolocation</b></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "35c4c985",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    violations_df[\"Geolocation\"] = violations_df[\"Geolocation\"].apply(format_and_clean_geolocation)\n",
    "\n",
    "    violations_df[\"Geolocation\"] = violations_df.apply(validate_geolocation, axis=1)\n",
    "\n",
    "    # Converting Tuple to String for database synchronization\n",
    "    violations_df[\"Geolocation\"] = violations_df[\"Geolocation\"].apply(geo_to_string)\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"Error while cleaning Geolocation column: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b097a1",
   "metadata": {},
   "source": [
    "<h1><b>Syncing violation_df with Database</b></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8c0e46cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Renaming columns for database synchronization\n",
    "    with open(\"./mappings/column_rename.json\", \"r\") as f:\n",
    "            mapping = json.load(f)\n",
    "    violations_df = violations_df.rename(columns=mapping)\n",
    "except FileNotFoundError:\n",
    "    raise FileNotFoundError(\"column_rename.json not found at ./mappings/column_rename.json\")\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"Error while renaming columns: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "84b41e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inserting violations data into the database\n",
    "from utils.db import get_engine\n",
    "\n",
    "try:\n",
    "    engine = get_engine()\n",
    "\n",
    "    violations_df.to_sql(\n",
    "        \"violations\",\n",
    "        engine,\n",
    "        if_exists=\"append\",\n",
    "        index=False,\n",
    "        method=\"multi\",\n",
    "        chunksize=5000\n",
    "    )\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"Failed to insert violations data: {e}\")\n",
    "finally:\n",
    "    if engine is not None: engine.dispose()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
